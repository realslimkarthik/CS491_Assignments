{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[398, 383, 394, 631, 168]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "\n",
    "# do something to prove it works\n",
    "rdd = sc.parallelize(range(1000))\n",
    "rdd.takeSample(False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    csv_reader = csv.reader(io.StringIO(line))\n",
    "    data_line = next(csv_reader)\n",
    "    return data_line[0], data_line[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_rdd = sc.textFile('./data/train.csv') \\\n",
    "    .map(parse_line) \\\n",
    "    .map(lambda record: (int(record[0]), record[1].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tweet Processing Functions\n",
    "\n",
    "Below are the definitions of the functions that are used to process the tweets before being sent on to feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.2.1.tar.gz (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 437kB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/55/0b/ce/960dcdaec7c9af5b1f81d471a90c8dae88374386efe6e54a50\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.2.1\n",
      "Requirement already satisfied (use --upgrade to upgrade): matplotlib in /opt/conda/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy>=1.6 in /opt/conda/lib/python3.5/site-packages (from matplotlib)\n",
      "Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /opt/conda/lib/python3.5/site-packages (from matplotlib)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pytz in /opt/conda/lib/python3.5/site-packages (from matplotlib)\n",
      "Requirement already satisfied (use --upgrade to upgrade): cycler in /opt/conda/lib/python3.5/site-packages (from matplotlib)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pyparsing!=2.0.4,>=1.5.6 in /opt/conda/lib/python3.5/site-packages (from matplotlib)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.5 in /opt/conda/lib/python3.5/site-packages (from python-dateutil->matplotlib)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade nltk\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/stopwords.txt') as stopword_file:\n",
    "    stopwords = {stopword.strip(): 1 for stopword in stopword_file.readlines()}\n",
    "    \n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def basic_cleaning(tweet):\n",
    "    clean_tweet = [word.lower().strip().strip('\\'').strip('\"') for word in tweet]\n",
    "    clean_tweet = [word.replace('.', '').replace('?', '').replace(',', '') for word in clean_tweet]\n",
    "    clean_tweet = [word.replace('#', '').replace('!', '').replace('\\'', '') for word in clean_tweet]\n",
    "    clean_tweet = [word.replace('\"', '').replace('...', ' ').replace('..', ' ') for word in clean_tweet]\n",
    "    clean_tweet = [word.replace('-', '').replace('.', ' ') for word in clean_tweet]\n",
    "    clean_tweet = list(filter(lambda word: word != '', clean_tweet))\n",
    "    \n",
    "    return clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_non_alpha_starting_words(tweet):\n",
    "    non_alpha_start_words_regex = '(^|\\s)[^a-zA-Z]\\w*($|\\s)'\n",
    "    clean_tweet = [re.sub(non_alpha_start_words_regex, '', word) for word in tweet]\n",
    "    clean_tweet = list(filter(lambda word: word != '', clean_tweet))\n",
    "\n",
    "    return clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(tweet):\n",
    "    tweet_without_stopwords = []\n",
    "    for word in tweet:\n",
    "        if word.find(' ') == -1:\n",
    "            new_word = word if word not in stopwords else ''\n",
    "        else:\n",
    "            new_word = ' '.join([w for w in word.split() if w not in stopwords])\n",
    "        tweet_without_stopwords.append(new_word)\n",
    "    tweet_without_stopwords = list(filter(lambda word: word != '', tweet_without_stopwords))\n",
    "    tweet_without_stopwords = list(set(tweet_without_stopwords))\n",
    "    return tweet_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_urls(tweet):\n",
    "    http_url_regex = 'http(?s):\\/\\/.*'\n",
    "    www_url_regex = 'www\\.\\w+.*'\n",
    "    clean_tweet = [re.sub(http_url_regex, 'URL', word) for word in tweet]\n",
    "    clean_tweet = [re.sub(www_url_regex, 'URL', word) for word in clean_tweet]\n",
    "    clean_tweet = list(filter(lambda word: word != '', clean_tweet))\n",
    "    \n",
    "    return clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_user_handles(tweet):\n",
    "    user_handle_regex = '@.*'\n",
    "    clean_tweet = [re.sub(user_handle_regex, 'AT_USER', word) for word in tweet]\n",
    "    clean_tweet = list(filter(lambda word: word != '', clean_tweet))\n",
    "\n",
    "    return clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_repeated_characters(tweet):\n",
    "    repeated_character_regex = '(\\w)\\\\1{2,}'\n",
    "    clean_tweet = [re.sub(repeated_character_regex, r'\\1\\1', word) for word in tweet]\n",
    "    clean_tweet = list(filter(lambda word: word != '', clean_tweet))\n",
    "\n",
    "    return clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_bigrams(tweet):\n",
    "    bigram_tweet = bigrams(tweet)\n",
    "    bigram_tweet = [bigram[0] + ' ' + bigram[1] for bigram in bigram_tweet]\n",
    "    bigram_tweet.extend(tweet)\n",
    "    return bigram_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_tweet(tweet, stemmer):\n",
    "    stemmed_tweet = []\n",
    "    for word in tweet:\n",
    "        if word.find(' ') == -1:\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "        else:\n",
    "            stemmed_word = ' '.join([stemmer.stem(w) for w in word.split()])\n",
    "        stemmed_tweet.append(stemmed_word)\n",
    "\n",
    "    return stemmed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_tweet_sentiment_rdd = tweet_rdd.map(lambda record: (record[0], replace_urls(record[1]))) \\\n",
    "    .map(lambda record: (record[0], replace_user_handles(record[1]))) \\\n",
    "    .map(lambda record: (record[0], basic_cleaning(record[1]))) \\\n",
    "    .map(lambda record: (record[0], remove_non_alpha_starting_words(record[1]))) \\\n",
    "    .map(lambda record: (record[0], replace_repeated_characters(record[1]))) \\\n",
    "    .map(lambda record: (record[0], generate_bigrams(record[1]))) \\\n",
    "    .map(lambda record: (record[0], remove_stopwords(record[1]))) \\\n",
    "    .map(lambda record: (record[0], stem_tweet(record[1], porter_stemmer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature Extraction using HashingTF and IDF\n",
    "\n",
    "This section consists of extracting features to be fed into our algorithms to generate the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_tweet_rdd = clean_tweet_sentiment_rdd.map(lambda record: record[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashingtf = HashingTF(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = hashingtf.transform(clean_tweet_rdd)\n",
    "tf.cache()\n",
    "idf = IDF(minDocFreq=2).fit(tf)\n",
    "tfidf = idf.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_idf_sentiment = clean_tweet_sentiment_rdd.map(lambda record: record[0]).zip(tfidf) \\\n",
    "    .map(lambda record: LabeledPoint(record[0], record[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = tf_idf_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "This section consists of the training of a Naive Bayes model and checking its accuracy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_model = NaiveBayes.train(training, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_labels_and_preds = training.map(lambda record: (nb_model.predict(record.features), record.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8819625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_accuracy = nb_labels_and_preds.filter(lambda x: x[0] == x[1]).count() / training.count()\n",
    "nb_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Logistic Regression\n",
    "\n",
    "This following section describes the Logistic Regression steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegressionWithLBFGS.train(training, regType='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_labels_and_preds = training.map(lambda record: (record.label, lr_model.predict(record.features)))\n",
    "trainErr = lr_labels_and_preds.filter(lambda record: record[0] != record[1]).count() / float(training.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0254375"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(k_value, model_type, data):\n",
    "    split_ratio = [0.1 for i in range(0, k_value)]\n",
    "    data_split = data.randomSplit(split_ratio)\n",
    "    test_index = 0\n",
    "    avg_accuracy = 0\n",
    "    best_model = None\n",
    "    for test_index in range(0, k_value):\n",
    "        print(str(test_index) + 'th iteration')\n",
    "        training_list = [i for index, i in enumerate(data_split) if index != test_index]\n",
    "        training_rdd = sc.emptyRDD()\n",
    "        for training in training_list:\n",
    "            training_rdd.union(training)\n",
    "        model = model_type.train(training, 1.0)\n",
    "        accuracy = test_with_model(model, data_split[test_index])\n",
    "        avg_accuracy += accuracy\n",
    "    \n",
    "    avg_accuracy /= k_value\n",
    "    \n",
    "    return avg_accuracy\n",
    "\n",
    "\n",
    "def test_with_model(model, test):\n",
    "    predictionAndLabel = test.map(lambda p: (model.predict(p.features), p.label))\n",
    "    accuracy = predictionAndLabel.filter(lambda x: x[0] == x[1]).count() / test.count()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th iteration\n",
      "1th iteration\n",
      "2th iteration\n",
      "3th iteration\n",
      "4th iteration\n",
      "5th iteration\n",
      "6th iteration\n",
      "7th iteration\n",
      "8th iteration\n",
      "9th iteration\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6454920921937479"
      ]
     },
     "execution_count": 894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_avg = k_fold_cross_validation(10, NaiveBayes, tf_idf_sentiment)\n",
    "NB_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th iteration\n",
      "1th iteration\n",
      "2th iteration\n",
      "3th iteration\n",
      "4th iteration\n",
      "5th iteration\n",
      "6th iteration\n",
      "7th iteration\n",
      "8th iteration\n",
      "9th iteration\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6784774653707852"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_avg = k_fold_cross_validation(10, LogisticRegressionWithLBFGS, tf_idf_sentiment)\n",
    "LR_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running classifiers on Test Data\n",
    "\n",
    "This section shows the results obtained by running the generated models on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_rdd = sc.textFile('./data/test.csv') \\\n",
    "    .map(parse_line) \\\n",
    "    .map(lambda record: (int(record[0]), record[1].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentiment_rdd = test_rdd.map(lambda record: (record[0], replace_urls(record[1]))) \\\n",
    "    .map(lambda record: (record[0], replace_user_handles(record[1]))) \\\n",
    "    .map(lambda record: (record[0], basic_cleaning(record[1]))) \\\n",
    "    .map(lambda record: (record[0], remove_non_alpha_starting_words(record[1]))) \\\n",
    "    .map(lambda record: (record[0], replace_repeated_characters(record[1]))) \\\n",
    "    .map(lambda record: (record[0], generate_bigrams(record[1]))) \\\n",
    "    .map(lambda record: (record[0], remove_stopwords(record[1]))) \\\n",
    "    .map(lambda record: (record[0], stem_tweet(record[1], porter_stemmer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_test_rdd = test_sentiment_rdd.map(lambda record: record[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tf = hashingtf.transform(clean_test_rdd)\n",
    "test_tf.cache()\n",
    "test_tfidf = idf.transform(test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tfidf_sentiment = test_sentiment_rdd.map(lambda record: record[0]).zip(test_tfidf) \\\n",
    "    .map(lambda record: LabeledPoint(record[0], record[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_labels_and_preds = test_tfidf_sentiment.map(lambda p: (nb_model.predict(p.features), p.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7103064066852368"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = nb_labels_and_preds.filter(lambda x: x[0] == x[1]).count() / test_tfidf_sentiment.count()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegressionWithLBFGS.train(training, regType='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_labels_and_preds = test_tfidf_sentiment.map(lambda record: (record.label, lr_model.predict(record.features)))\n",
    "trainErr = lr_labels_and_preds.filter(lambda record: record[0] != record[1]).count() / float(test_tfidf_sentiment.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2618384401114206"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainErr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Evaluation of Classifiers\n",
    "\n",
    "This section covers capturing of the various performance metrics that the algorithms achieve on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def precision(labels_and_preds):\n",
    "    classified_1s = list(filter(lambda line: line[1] == 1, labels_and_preds))\n",
    "    classified_0s = list(filter(lambda line: line[1] == 0, labels_and_preds))\n",
    "    correctly_predicted_1s = len(list(filter(lambda line: line[0] == line[1], classified_1s)))\n",
    "    correctly_predicted_0s = len(list(filter(lambda line: line[0] == line[1], classified_0s)))\n",
    "    precision_1s = correctly_predicted_1s / len(classified_1s)\n",
    "    precision_0s = correctly_predicted_0s / len(classified_0s)\n",
    "    \n",
    "    return {'p1': precision_1s, 'p0': precision_0s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(labels_and_preds):\n",
    "    actual_1s = list(filter(lambda line: line[0] == 1, labels_and_preds))\n",
    "    actual_0s = list(filter(lambda line: line[0] == 0, labels_and_preds))\n",
    "    correctly_predicted_1s = len(list(filter(lambda line: line[0] == line[1], actual_1s)))\n",
    "    correctly_predicted_0s = len(list(filter(lambda line: line[0] == line[1], actual_0s)))\n",
    "    recall_1s = correctly_predicted_1s / len(actual_1s)\n",
    "    recall_0s = correctly_predicted_0s / len(actual_0s)\n",
    "    \n",
    "    return {'r1': recall_1s, 'r0': recall_0s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(labels_and_preds):\n",
    "    actual_1s = list(filter(lambda line: line[0] == 1, labels_and_preds))\n",
    "    actual_0s = list(filter(lambda line: line[0] == 0, labels_and_preds))\n",
    "    correctly_predicted_1s = len(list(filter(lambda line: line[0] == line[1], actual_1s)))\n",
    "    correctly_predicted_0s = len(list(filter(lambda line: line[0] == line[1], actual_0s)))\n",
    "    incorrectly_predicted_1s = len(list(filter(lambda line: line[0] != line[1], actual_1s)))\n",
    "    incorrectly_predicted_0s = len(list(filter(lambda line: line[0] != line[1], actual_0s)))\n",
    "    \n",
    "    return {'correct_1s': correctly_predicted_1s, 'correct_0s': correctly_predicted_0s, \\\n",
    "            'incorrect_1s': incorrectly_predicted_1s, 'incorrect_0s': incorrectly_predicted_0s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_precisions = precision(nb_labels_and_preds.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_precisions = precision(lr_labels_and_preds.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_recalls = recall(nb_labels_and_preds.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_recalls = recall(lr_labels_and_preds.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6538461538461539, 0.768361581920904)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_precisions['p1'], nb_precisions['p0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.74375, 0.6834170854271356)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_recalls['r1'], nb_recalls['r0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7417582417582418, 0.7344632768361582)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_precisions['p1'], lr_precisions['p0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7417582417582418, 0.7344632768361582)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_recalls['r1'], lr_recalls['r0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_conf_matrix = generate_confusion_matrix(nb_labels_and_preds.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_conf_matrix = generate_confusion_matrix(lr_labels_and_preds.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct_0s': 136, 'correct_1s': 119, 'incorrect_0s': 63, 'incorrect_1s': 41}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct_0s': 130, 'correct_1s': 135, 'incorrect_0s': 47, 'incorrect_1s': 47}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Tweets with the Highest Prediction Probabilities\n",
    "\n",
    "This section calculates the Tweets with the highest prediction probabilities for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegressionWithLBFGS.train(training, regType='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_labels_and_preds = test_tfidf_sentiment.map(lambda record: (record.label, lr_model.predict(record.features)))\n",
    "trainErr = lr_labels_and_preds.filter(lambda record: record[0] != record[1]).count() / float(test_tfidf_sentiment.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_lnpred_list = lr_labels_and_preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_model.clearThreshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_labels_and_probs = test_tfidf_sentiment.map(lambda record: (record.label, lr_model.predict(record.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_lnprob_list = lr_labels_and_probs.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_highest_probs(labels_and_preds, labels_and_probs, tweets_list):\n",
    "    lr_lnpredprob_list = [(r1[0], r1[1], r2[1])for r1, r2 in zip(labels_and_preds, labels_and_probs)]\n",
    "    lr_lnpredprob_list = [(index, val[0], val[1], val[2]) for index, val in enumerate(lr_lnpredprob_list)]\n",
    "        \n",
    "    lr_pred_prob_correct = list(sorted(filter(lambda record: record[1] == record[2], lr_lnpredprob_list), key=itemgetter(3), \\\n",
    "                           reverse=True))\n",
    "    lr_pred_prob_incorrect = list(sorted(filter(lambda record: record[1] != record[2], lr_lnpredprob_list), key=itemgetter(3), \\\n",
    "                                    reverse=True))\n",
    "    \n",
    "    tweets_with_pred_probs = {'correct': [], 'incorrect': []}\n",
    "\n",
    "    for record in lr_pred_prob_correct[:5]:\n",
    "        tweets_with_pred_probs['correct'].append({'text': ' '.join(tweets_list[record[0]][1]), 'prob': record[3]})\n",
    "\n",
    "    for record in lr_pred_prob_incorrect[:5]:\n",
    "        tweets_with_pred_probs['incorrect'].append({'text': ' '.join(tweets_list[record[0]][1]), 'prob': record[3]})\n",
    "    \n",
    "    return tweets_with_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "highest_prob_tweets = calculate_highest_probs(lr_lnpred_list, lr_lnprob_list, tweet_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': [{'prob': 0.9999999988837434,\n",
       "   'text': '@David_Henrie *thats people mag haha i couldnt fit it all in.. i dont think those pictures ever made it in the magazine tho! haha'},\n",
       "  {'prob': 0.999999392838995,\n",
       "   'text': 'i had 7 hours of sleep and now i cant go back to sleeping im thirsty'},\n",
       "  {'prob': 0.9999984609403177,\n",
       "   'text': '@duchess_rebecca Man... intervention is soo sad'},\n",
       "  {'prob': 0.9999971741610747,\n",
       "   'text': 'iiiii havent slept yet and i have to be at work in 40 minutes. boo'},\n",
       "  {'prob': 0.9999955435455488,\n",
       "   'text': 'going, going, aaand gone. poor moosie fell asleep in class http://twitpic.com/2y82y'}],\n",
       " 'incorrect': [{'prob': 0.9996191051874458,\n",
       "   'text': 'Stuck at home I watch way to many border patrol programs..watching a new zeland one now. What the hell is MAF?'},\n",
       "  {'prob': 0.9992751969020601,\n",
       "   'text': \"@griffmiester no exchanging for me, my laptop hasn't arrived\"},\n",
       "  {'prob': 0.9987971855520478,\n",
       "   'text': 'Feeling soree, bad idea to go running when your sick'},\n",
       "  {'prob': 0.9964657772968846,\n",
       "   'text': \"@jemcam well i have uni stuff and netball but after netbal if i've done uni stuff we can\"},\n",
       "  {'prob': 0.9964626563694955,\n",
       "   'text': '@duncn Revision, again. Oh, and morning @itscammy!'}]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_prob_tweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
